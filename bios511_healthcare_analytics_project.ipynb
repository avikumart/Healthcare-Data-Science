{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ymsozqm6J6eq"
      },
      "outputs": [],
      "source": [
        "title: \"Health & Lifestyle Data Analysis and ML Pipeline\" output: html_document date: \"r Sys.Date()\"knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)\n",
        "1. Library ImportsWe will use the tidyverse for data manipulation and plotting, aws.s3 for loading data from AWS, and the tidymodels ecosystem (including themis for SMOTE) for machine learning.# Install packages if not already installed\n",
        "if (!require(\"pacman\")) install.packages(\"pacman\")\n",
        "pacman::p_load(\n",
        "  tidyverse,    # Data manipulation and visualization\n",
        "  aws.s3,       # AWS S3 connectivity (replaces boto3)\n",
        "  tidymodels,   # Machine Learning framework (replaces sklearn)\n",
        "  themis,       # For SMOTE (replaces imblearn)\n",
        "  corrplot,     # For correlation heatmaps\n",
        "  dotenv        # For environment variables\n",
        ")\n",
        "\n",
        "# Load environment variables if .env exists\n",
        "tryCatch({\n",
        "  load_dot_env()\n",
        "}, error = function(e) {\n",
        "  message(\"No .env file found or error loading it.\")\n",
        "})\n",
        "2. Data LoadingThis section connects to AWS S3 to retrieve the dataset, mirroring the boto3 logic in the original code.# Specify bucket and file key\n",
        "bucket_name <- 'dw-health-lifestyle-dataset'\n",
        "file_key <- 'health_lifestyle_dataset.csv'\n",
        "\n",
        "# Retrieve keys from environment variables\n",
        "# Note: In R, use Sys.getenv()\n",
        "aws_access_key <- Sys.getenv(\"aws_access_key_id\")\n",
        "aws_secret_key <- Sys.getenv(\"aws_secret_access_key\")\n",
        "\n",
        "# Function to load data\n",
        "load_data_from_s3 <- function() {\n",
        "  tryCatch({\n",
        "    # Set AWS environment variables for the session\n",
        "    Sys.setenv(\n",
        "      \"AWS_ACCESS_KEY_ID\" = aws_access_key,\n",
        "      \"AWS_SECRET_ACCESS_KEY\" = aws_secret_key,\n",
        "      \"AWS_DEFAULT_REGION\" = \"us-east-2\"\n",
        "    )\n",
        "\n",
        "    if (aws_access_key != \"\" && aws_secret_key != \"\") {\n",
        "        print(paste(\"Successful S3 connection. Loading\", file_key, \"...\"))\n",
        "\n",
        "        # Read object from S3\n",
        "        obj <- get_object(object = file_key, bucket = bucket_name)\n",
        "\n",
        "        # Parse CSV content\n",
        "        raw_data <- rawToChar(obj)\n",
        "        df <- read.csv(text = raw_data)\n",
        "        return(df)\n",
        "    } else {\n",
        "        print(\"AWS Credentials not found. Loading dummy data or checking local path.\")\n",
        "        # Fallback or Placeholder if keys aren't present in this run\n",
        "        return(NULL)\n",
        "    }\n",
        "\n",
        "  }, error = function(e) {\n",
        "    print(paste(\"Error:\", e$message))\n",
        "    return(NULL)\n",
        "  })\n",
        "}\n",
        "\n",
        "# Attempt to load data\n",
        "df <- load_data_from_s3()\n",
        "\n",
        "# If S3 fails (e.g., no creds in this env), ensure df exists for the rest of the notebook to run syntax checks\n",
        "if (is.null(df)) {\n",
        "    warning(\"Data could not be loaded from S3. Please ensure credentials are set.\")\n",
        "} else {\n",
        "    print(head(df))\n",
        "}\n",
        "3. Exploratory Data Analysis (EDA)Checking structure, missing values, and statistics.if (!is.null(df)) {\n",
        "  # Check structure (equivalent to df.info())\n",
        "  str(df)\n",
        "\n",
        "  # Check missing values\n",
        "  print(\"Missing Values:\")\n",
        "  print(colSums(is.na(df)))\n",
        "\n",
        "  # Basic statistics (equivalent to df.describe())\n",
        "  print(\"Summary Statistics:\")\n",
        "  summary(df)\n",
        "\n",
        "  # Remove duplicates\n",
        "  initial_rows <- nrow(df)\n",
        "  df <- df %>% distinct()\n",
        "  print(paste(\"Duplicates removed:\", initial_rows - nrow(df)))\n",
        "\n",
        "  # Drop ID column if it exists\n",
        "  if (\"id\" %in% names(df)) {\n",
        "    df <- df %>% select(-id)\n",
        "  }\n",
        "}\n",
        "Visualization FunctionsDefining R equivalents for the Python plotting functions using ggplot2.# Function to plot distribution\n",
        "plot_distribution <- function(data, column) {\n",
        "  p <- ggplot(data, aes_string(x = column)) +\n",
        "    geom_histogram(aes(y = ..density..), fill = \"skyblue\", color = \"black\", bins = 30) +\n",
        "    geom_density(color = \"red\", size = 1) +\n",
        "    labs(title = paste(\"Distribution of\", column), x = column, y = \"Frequency\") +\n",
        "    theme_minimal()\n",
        "  print(p)\n",
        "}\n",
        "\n",
        "# Function to plot correlation heatmap\n",
        "plot_correlation_heatmap <- function(data) {\n",
        "  # Select numeric columns\n",
        "  nums <- unlist(lapply(data, is.numeric))\n",
        "  numeric_data <- data[, nums]\n",
        "\n",
        "  # Calculate correlation\n",
        "  corr_matrix <- cor(numeric_data, use = \"complete.obs\")\n",
        "\n",
        "  # Plot\n",
        "  corrplot(corr_matrix, method = \"color\", type = \"upper\",\n",
        "           addCoef.col = \"black\", tl.col = \"black\", tl.srt = 45,\n",
        "           title = \"Correlation Heatmap\", mar = c(0,0,1,0))\n",
        "}\n",
        "\n",
        "# Function to plot boxplot\n",
        "plot_boxplot <- function(data, column) {\n",
        "  p <- ggplot(data, aes_string(y = column)) +\n",
        "    geom_boxplot(fill = \"lightgreen\") +\n",
        "    labs(title = paste(\"Boxplot of\", column), y = column) +\n",
        "    theme_minimal()\n",
        "  print(p)\n",
        "}\n",
        "\n",
        "# Function to map relation of disease_risk with other columns\n",
        "# Using stat_summary to mimic seaborn pointplot (mean with error bars)\n",
        "plot_disease_risk_relation <- function(data, column) {\n",
        "  p <- ggplot(data, aes_string(x = column, y = \"disease_risk\")) +\n",
        "    stat_summary(fun.data = \"mean_se\", geom = \"pointrange\", color = \"blue\") +\n",
        "    stat_summary(fun = \"mean\", geom = \"line\", group = 1, color = \"blue\") +\n",
        "    labs(title = paste(\"Relation of\", column, \"with Disease Risk\"),\n",
        "         x = column, y = \"Disease Risk (Mean)\") +\n",
        "    theme_minimal()\n",
        "  print(p)\n",
        "}\n",
        "\n",
        "# Function to plot categorical count\n",
        "plot_categorical_count <- function(data, column) {\n",
        "  p <- ggplot(data, aes_string(x = column)) +\n",
        "    geom_bar(fill = \"orange\", color = \"black\") +\n",
        "    labs(title = paste(\"Count of\", column), x = column, y = \"Count\") +\n",
        "    theme_minimal() +\n",
        "    theme(axis.text.x = element_text(angle = 45, hjust = 1))\n",
        "  print(p)\n",
        "}\n",
        "Visualizing the Dataif (!is.null(df)) {\n",
        "  plot_distribution(df, 'age')\n",
        "  plot_correlation_heatmap(df)\n",
        "  plot_boxplot(df, 'age')\n",
        "  plot_categorical_count(df, 'gender')\n",
        "\n",
        "  # Relations\n",
        "  plot_disease_risk_relation(df, 'resting_hr')\n",
        "  plot_disease_risk_relation(df, 'smoker')\n",
        "  plot_disease_risk_relation(df, 'alcohol')\n",
        "  plot_disease_risk_relation(df, 'age')\n",
        "\n",
        "  # Check Target Balance\n",
        "  print(\"Target Variable Counts:\")\n",
        "  print(table(df$disease_risk))\n",
        "}\n",
        "4. Machine Learning PipelineWe will use tidymodels to replicate the sklearn pipeline. This handles splitting, preprocessing (scaling/encoding), SMOTE oversampling, and model training.Data Splittingif (!is.null(df)) {\n",
        "  # Ensure target is a factor for classification\n",
        "  df$disease_risk <- as.factor(df$disease_risk)\n",
        "\n",
        "  set.seed(42)\n",
        "  # Split: 80% Train, 20% Test, stratified by target\n",
        "  split <- initial_split(df, prop = 0.8, strata = disease_risk)\n",
        "  train_data <- training(split)\n",
        "  test_data <- testing(split)\n",
        "\n",
        "  print(paste(\"Training set size:\", nrow(train_data)))\n",
        "  print(paste(\"Testing set size:\", nrow(test_data)))\n",
        "}\n",
        "Feature Engineering & Pipeline DefinitionWe define a recipe that performs:One-Hot Encoding (Dummy variables)Normalization (StandardScaler)SMOTE (Oversampling)if (!is.null(df)) {\n",
        "  # Define the recipe\n",
        "  ml_recipe <- recipe(disease_risk ~ ., data = train_data) %>%\n",
        "    # Encode categorical variables (OneHotEncoder)\n",
        "    step_dummy(all_nominal_predictors()) %>%\n",
        "    # Normalize numeric variables (StandardScaler)\n",
        "    step_normalize(all_numeric_predictors()) %>%\n",
        "    # Apply SMOTE for class imbalance\n",
        "    step_smote(disease_risk, seed = 42)\n",
        "}\n",
        "Model SpecificationsDefining Logistic Regression and Random Forest.# Logistic Regression\n",
        "log_spec <- logistic_reg() %>%\n",
        "  set_engine(\"glm\") %>%\n",
        "  set_mode(\"classification\")\n",
        "\n",
        "# Random Forest\n",
        "rf_spec <- rand_forest(trees = 100) %>%\n",
        "  set_engine(\"ranger\", importance = \"impurity\") %>% # 'ranger' is a fast R implementation\n",
        "  set_mode(\"classification\")\n",
        "Cross Validation and TrainingWe perform 5-fold cross-validation on the training set.if (!is.null(df)) {\n",
        "  print(\"Starting Model Training with SMOTE...\")\n",
        "\n",
        "  set.seed(42)\n",
        "  folds <- vfold_cv(train_data, v = 5, strata = disease_risk)\n",
        "\n",
        "  # 1. Logistic Regression Workflow\n",
        "  log_ wf <- workflow() %>%\n",
        "    add_recipe(ml_recipe) %>%\n",
        "    add_model(log_spec)\n",
        "\n",
        "  log_res <- fit_resamples(\n",
        "    log_wf,\n",
        "    resamples = folds,\n",
        "    metrics = metric_set(f1, accuracy, recall, roc_auc),\n",
        "    control = control_resamples(save_pred = TRUE)\n",
        "  )\n",
        "\n",
        "  print(\"--- Logistic Regression CV Results ---\")\n",
        "  print(collect_metrics(log_res) %>% select(.metric, mean))\n",
        "\n",
        "  # 2. Random Forest Workflow\n",
        "  rf_wf <- workflow() %>%\n",
        "    add_recipe(ml_recipe) %>%\n",
        "    add_model(rf_spec)\n",
        "\n",
        "  rf_res <- fit_resamples(\n",
        "    rf_wf,\n",
        "    resamples = folds,\n",
        "    metrics = metric_set(f1, accuracy, recall, roc_auc)\n",
        "  )\n",
        "\n",
        "  print(\"--- Random Forest CV Results ---\")\n",
        "  print(collect_metrics(rf_res) %>% select(.metric, mean))\n",
        "}\n",
        "5. Final Evaluation on Test SetTraining on the full training data and predicting on the held-out test set.if (!is.null(df)) {\n",
        "\n",
        "  evaluate_model <- function(workflow, name) {\n",
        "    # Fit on training, predict on test\n",
        "    final_fit <- last_fit(workflow, split, metrics = metric_set(accuracy, recall, f1, roc_auc))\n",
        "\n",
        "    # Extract metrics\n",
        "    metrics <- collect_metrics(final_fit)\n",
        "\n",
        "    print(paste(\"--- Final Test Results:\", name, \"---\"))\n",
        "    print(metrics)\n",
        "\n",
        "    return(final_fit)\n",
        "  }\n",
        "\n",
        "  log_final <- evaluate_model(log_wf, \"Logistic Regression\")\n",
        "  rf_final <- evaluate_model(rf_wf, \"Random Forest\")\n",
        "\n",
        "  # Feature Importance for Random Forest (Best Model analysis equivalent)\n",
        "  # Extract the fitted model object\n",
        "  fitted_rf <- extract_fit_parsnip(rf_final)\n",
        "\n",
        "  print(\"Variable Importance (Random Forest):\")\n",
        "  # Using vip package if available, or extracting from ranger object\n",
        "  if (require(\"vip\")) {\n",
        "    print(vip::vip(fitted_rf))\n",
        "  } else {\n",
        "    print(fitted_rf$fit$variable.importance)\n",
        "  }\n",
        "\n",
        "  # Coefficients for Logistic Regression\n",
        "  fitted_log <- extract_fit_parsnip(log_final)\n",
        "  print(\"Coefficients (Logistic Regression):\")\n",
        "  print(tidy(fitted_log))\n",
        "}\n"
      ]
    }
  ]
}